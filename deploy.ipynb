{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.100:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/novachrono/Library/Python/3.11/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/novachrono/Library/Python/3.11/lib/python/site-packages/traitlets/config/application.py\", line 1052, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/Users/novachrono/Library/Python/3.11/lib/python/site-packages/traitlets/config/application.py\", line 117, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/novachrono/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 689, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/Users/novachrono/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 328, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/novachrono/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 252, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/novachrono/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 228, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/Users/novachrono/Library/Python/3.11/lib/python/site-packages/zmq/sugar/socket.py\", line 302, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 564, in zmq.backend.cython.socket.Socket.bind\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9007')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/novachrono/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from scipy.optimize import linprog\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load trained XGBoost model\n",
    "model_path = \"./xgb_model.pkl\"\n",
    "xgb_model = joblib.load(model_path)\n",
    "\n",
    "# Function to preprocess input features\n",
    "def preprocess_input(data):\n",
    "    \"\"\"\n",
    "    Convert natural language input or CSV data into structured model features.\n",
    "    \"\"\"\n",
    "    # Ensure necessary columns exist\n",
    "    required_columns = ['latency_ms', 'packet_loss_rate_percent', 'load_percent', 'active_users',\n",
    "                        'spectrum_mhz', 'handover_attempts', 'handover_failures', 'rsrp_dBm',\n",
    "                        'rsrq_dB', 'sinr_dB', 'spectrum_utilization_percent', 'congestion_level_percent']\n",
    "    \n",
    "    for col in required_columns:\n",
    "        if col not in data:\n",
    "            data[col] = 0  # Default missing values to 0\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Function for LP-based resource allocation\n",
    "def allocate_resources(df):\n",
    "    df['total_capacity'] = 1 * (1 - df[\"spectrum_utilization_percent\"]) * (1 - df[\"load_percent\"])\n",
    "    df[\"available_capacity\"] = df[\"total_capacity\"] * (1 - df[\"spectrum_utilization_percent\"]) * (1 - df[\"load_percent\"])\n",
    "    \n",
    "    # LP Optimization Setup\n",
    "    c = -df[\"model_prediction\"].values  # Objective: Maximize allocation\n",
    "    num_cells = len(df)\n",
    "    A_ub = np.eye(num_cells)\n",
    "    b_ub = np.minimum(df[\"available_capacity\"].values, df['total_capacity'] * 0.7)  # 70% max allocation\n",
    "    \n",
    "    result = linprog(c, A_ub=A_ub, b_ub=b_ub, method='highs')\n",
    "    df[\"allocated_resources\"] = result.x if result.success else np.zeros(num_cells)\n",
    "    return df\n",
    "\n",
    "# API Endpoint: Predict single query\n",
    "@app.route('/predict_single', methods=['POST'])\n",
    "def predict_single():\n",
    "    try:\n",
    "        data = request.json\n",
    "        data = preprocess_input(data)\n",
    "        df = pd.DataFrame([data])\n",
    "        prediction = xgb_model.predict(df)[0]\n",
    "        df[\"model_prediction\"] = prediction\n",
    "        df = allocate_resources(df)\n",
    "        return jsonify({\"predicted_traffic_mbps\": prediction, \"allocated_resources_mbps\": df[\"allocated_resources\"].values[0]})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "# API Endpoint: Batch CSV processing\n",
    "@app.route('/predict_batch', methods=['POST'])\n",
    "def predict_batch():\n",
    "    try:\n",
    "        file = request.files['file']\n",
    "        df = pd.read_csv(file)\n",
    "        df = preprocess_input(df)\n",
    "        df['model_prediction'] = xgb_model.predict(df)\n",
    "        df = allocate_resources(df)\n",
    "        output_path = \"./output/predictions.csv\"\n",
    "        os.makedirs(\"./output\", exist_ok=True)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        return jsonify({\"message\": \"Batch processing complete\", \"download_link\": output_path})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.100:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [15/Mar/2025 18:13:40] \"POST /predict_single HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Mar/2025 18:13:49] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from scipy.optimize import linprog\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Root endpoint to check if API is running\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Flask API is running!\"\n",
    "\n",
    "# Load trained XGBoost model\n",
    "model_path = \"./xgb_model.pkl\"\n",
    "xgb_model = joblib.load(model_path)\n",
    "\n",
    "# Function to preprocess input features\n",
    "def preprocess_input(data):\n",
    "    \"\"\"\n",
    "    Convert natural language input or CSV data into structured model features.\n",
    "    \"\"\"\n",
    "    required_columns = [\n",
    "        'Unnamed: 0', 'latency_ms', 'packet_loss_rate_percent', 'load_percent', 'active_users',\n",
    "        'spectrum_mhz', 'handover_attempts', 'handover_failures', 'rsrp_dBm', 'rsrq_dB',\n",
    "        'sinr_dB', 'spectrum_utilization_percent', 'congestion_level_percent', 'year_x', 'month_x',\n",
    "        'week_x', 'daily_x', 'hour_x', 'dayofweek_x', 'lag_1_x', 'lag_3_x', 'sin_day_of_week_x',\n",
    "        'cos_day_of_week_x', 'band_Band1', 'band_Band2', 'band_Band3', 'issue_description_Equipment failure',\n",
    "        'issue_description_Network instability', 'issue_description_Overload', 'issue_description_Signal loss',\n",
    "        'year_y', 'month_y', 'week_y', 'daily_y', 'hour_y', 'dayofweek_y', 'lag_1_y', 'lag_3_y',\n",
    "        'sin_day_of_week_y', 'cos_day_of_week_y'\n",
    "    ]\n",
    "    df = pd.DataFrame([data]) if isinstance(data, dict) else data\n",
    "    \n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0  # Fill missing columns with default value\n",
    "    \n",
    "    return df[required_columns]  # Ensure correct column order\n",
    "\n",
    "# Function for LP-based resource allocation\n",
    "def allocate_resources(df):\n",
    "    df['total_capacity'] = 1 * (1 - df[\"spectrum_utilization_percent\"]) * (1 - df[\"load_percent\"])\n",
    "    df[\"available_capacity\"] = df[\"total_capacity\"] * (1 - df[\"spectrum_utilization_percent\"]) * (1 - df[\"load_percent\"])\n",
    "    \n",
    "    # LP Optimization Setup\n",
    "    c = -df[\"model_prediction\"].values  # Objective: Maximize allocation\n",
    "    num_cells = len(df)\n",
    "    A_ub = np.eye(num_cells)\n",
    "    b_ub = np.minimum(df[\"available_capacity\"].values, df['total_capacity'] * 0.7)  # 70% max allocation\n",
    "    \n",
    "    result = linprog(c, A_ub=A_ub, b_ub=b_ub, method='highs')\n",
    "    df[\"allocated_resources\"] = result.x if result.success else np.zeros(num_cells)\n",
    "    return df\n",
    "\n",
    "# API Endpoint: Predict single query\n",
    "@app.route('/predict_single', methods=['POST'])\n",
    "def predict_single():\n",
    "    try:\n",
    "        data = request.json\n",
    "        df = preprocess_input(data)\n",
    "        prediction = float(xgb_model.predict(df)[0])  # Convert float32 to standard float\n",
    "        df[\"model_prediction\"] = prediction\n",
    "        df = allocate_resources(df)\n",
    "        allocated_resources = float(df[\"allocated_resources\"].values[0])  # Convert to standard float\n",
    "        return jsonify({\"predicted_traffic_mbps\": prediction, \"allocated_resources_mbps\": allocated_resources})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "\n",
    "# API Endpoint: Batch CSV processing\n",
    "@app.route('/predict_batch', methods=['POST'])\n",
    "def predict_batch():\n",
    "    try:\n",
    "        file = request.files['file']\n",
    "        df = pd.read_csv(file)\n",
    "        df = preprocess_input(df)\n",
    "        df['model_prediction'] = xgb_model.predict(df)\n",
    "        df = allocate_resources(df)\n",
    "        output_path = \"./output/predictions.csv\"\n",
    "        os.makedirs(\"./output\", exist_ok=True)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        return jsonify({\"message\": \"Batch processing complete\", \"download_link\": output_path})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/novachrono/Library/Python/3.11/lib/python/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandasai.llm.huggingface'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandasai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFace\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandasai.llm.huggingface'"
     ]
    }
   ],
   "source": [
    "from pandasai.llm.huggingface import HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandasai.llm.huggingface'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandasai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SmartDataframe\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandasai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFace  \u001b[38;5;66;03m# Use Hugging Face model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize Flask app\u001b[39;00m\n\u001b[1;32m      8\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m, template_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplates\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandasai.llm.huggingface'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm.huggingface import HuggingFace  # Use Hugging Face model\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__, template_folder=\"templates\")\n",
    "\n",
    "# Load CSV file at startup\n",
    "data_path = \"./test_set_feature_prediction_2.csv\"  # Ensure this file exists\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# Initialize PandasAI for AI-powered CSV querying\n",
    "llm = HuggingFace(model_name=\"tiiuae/falcon-7b-instruct\")  # Replace with a suitable free model\n",
    "df_ai = SmartDataframe(df, config={\"llm\": llm})\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "# API Endpoint: Query CSV with AI based on cell ID\n",
    "@app.route('/query_csv', methods=['POST'])\n",
    "def query_csv():\n",
    "    try:\n",
    "        query = request.json.get(\"query\", \"\")\n",
    "        if not query:\n",
    "            return jsonify({\"error\": \"No query provided\"})\n",
    "        \n",
    "        result = df_ai.chat(query)\n",
    "        return jsonify({\"response\": str(result)})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "# API Endpoint: Chatbot for cell-based queries\n",
    "@app.route('/chatbot', methods=['POST'])\n",
    "def chatbot():\n",
    "    try:\n",
    "        user_query = request.json.get(\"query\", \"\").lower()\n",
    "        if not user_query:\n",
    "            return jsonify({\"error\": \"No query provided\"})\n",
    "        \n",
    "        # Extract cell ID from user query\n",
    "        words = user_query.split()\n",
    "        cell_id = next((word for word in words if word.isdigit()), None)\n",
    "        \n",
    "        if cell_id is None:\n",
    "            return jsonify({\"error\": \"No valid cell ID found in query\"})\n",
    "        \n",
    "        # Search for the cell ID in the CSV\n",
    "        cell_data = df[df['cellid'].astype(str) == cell_id]\n",
    "        if cell_data.empty:\n",
    "            return jsonify({\"error\": f\"Cell ID {cell_id} not found in data\"})\n",
    "        \n",
    "        # Extract network usage and allocated resources\n",
    "        predicted_traffic = cell_data['predicted_traffic_mbps'].values[0]\n",
    "        allocated_resources = cell_data['allocated_resources_mbps'].values[0]\n",
    "        \n",
    "        response = {\n",
    "            \"query\": user_query,\n",
    "            \"cell_id\": cell_id,\n",
    "            \"predicted_traffic_mbps\": predicted_traffic,\n",
    "            \"allocated_resources_mbps\": allocated_resources\n",
    "        }\n",
    "        return jsonify(response)\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/novachrono/Library/Python/3.11/lib/python/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-macosx_10_9_x86_64.whl (287 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl (436 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-macosx_10_12_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.29.3 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.49.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.100:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [16/Mar/2025 10:54:34] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 10:54:45] \"POST /query_csv HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__, template_folder=\"templates\")\n",
    "\n",
    "# Load CSV file\n",
    "data_path = \"./ResourceAllocation.csv\"\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "# API Endpoint: Query CSV by cell_id\n",
    "@app.route('/query_csv', methods=['POST'])\n",
    "def query_csv():\n",
    "    try:\n",
    "        cell_id = request.json.get(\"cell_id\", \"\").lower()\n",
    "        if not cell_id:\n",
    "            return jsonify({\"error\": \"No cell_id provided\"})\n",
    "\n",
    "        if df.empty:\n",
    "            return jsonify({\"error\": \"CSV file is empty or missing\"})\n",
    "\n",
    "        df[\"cell_id\"] = df[\"cell_id\"].astype(str).str.lower()\n",
    "        filtered_df = df[df[\"cell_id\"] == cell_id]\n",
    "        \n",
    "        if filtered_df.empty:\n",
    "            return jsonify({\"error\": \"No matching cell_id found\"})\n",
    "        \n",
    "        latest_entry = filtered_df.sort_values(by=\"timestamp\", ascending=False).iloc[0]\n",
    "        model_prediction = latest_entry[\"model_prediction\"]\n",
    "        capacity_allocated = latest_entry[\"Capacity_Allocated(Mbps)\"]\n",
    "        \n",
    "        response_text = (f\"For cell {cell_id}, the predicted network traffic is {model_prediction}, \"\n",
    "                         f\"and the needed resource for this traffic is {capacity_allocated} Mbps.\")\n",
    "        \n",
    "        return jsonify({\"response\": response_text})\n",
    "    except Exception as e:b\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.100:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [16/Mar/2025 11:39:31] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Mar/2025 11:39:31] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [16/Mar/2025 11:39:31] \"\u001b[36mGET /static/mtn-logo.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [16/Mar/2025 11:39:51] \"POST /upload_csv HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template, send_file\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__, template_folder=\"templates\", static_folder=\"static\")\n",
    "\n",
    "# Load CSV file\n",
    "data_path = \"./ResourceAllocation.csv\"\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "# API Endpoint: Query CSV by cell_id\n",
    "@app.route('/query_csv', methods=['POST'])\n",
    "def query_csv():\n",
    "    try:\n",
    "        cell_id = request.json.get(\"cell_id\", \"\").strip().lower()\n",
    "        if not cell_id:\n",
    "            return jsonify({\"error\": \"No cell_id provided\"})\n",
    "\n",
    "        if df.empty:\n",
    "            return jsonify({\"error\": \"CSV file is empty or missing\"})\n",
    "\n",
    "        if \"cell_id\" not in df.columns or \"model_prediction\" not in df.columns or \"Capacity_Allocated(Mbps)\" not in df.columns:\n",
    "            return jsonify({\"error\": \"CSV file does not have the required columns\"})\n",
    "\n",
    "        df[\"cell_id\"] = df[\"cell_id\"].astype(str).str.lower()\n",
    "        filtered_df = df[df[\"cell_id\"] == cell_id]\n",
    "        \n",
    "        if filtered_df.empty:\n",
    "            return jsonify({\"error\": \"No matching cell_id found\"})\n",
    "        \n",
    "        latest_entry = filtered_df.sort_values(by=\"timestamp\", ascending=False).iloc[0]\n",
    "        network_traffic_usage = latest_entry.get(\"model_prediction\", \"N/A\")\n",
    "        resource_allocation = latest_entry.get(\"Capacity_Allocated(Mbps)\", \"N/A\")\n",
    "        timestamp_label = latest_entry.get(\"timestamp\", \"N/A\")\n",
    "        \n",
    "        response_text = (f\"For cell {cell_id}, the predicted network traffic usage is {network_traffic_usage}, \"\n",
    "                         f\"and the needed resource allocation for this traffic is {resource_allocation} Mbps.\")\n",
    "        \n",
    "        return jsonify({\"response\": response_text})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "# API Endpoint: Process CSV Upload\n",
    "@app.route('/upload_csv', methods=['POST'])\n",
    "def upload_csv():\n",
    "    try:\n",
    "        if 'file' not in request.files:\n",
    "            return jsonify({\"error\": \"No file uploaded\"})\n",
    "        \n",
    "        file = request.files['file']\n",
    "        if file.filename == '':\n",
    "            return jsonify({\"error\": \"No selected file\"})\n",
    "        \n",
    "        input_df = pd.read_csv(file)\n",
    "        if \"cell_id\" not in input_df.columns:\n",
    "            return jsonify({\"error\": \"CSV must contain a 'cell_id' column\"})\n",
    "        \n",
    "        input_df[\"cell_id\"] = input_df[\"cell_id\"].astype(str).str.lower()\n",
    "        df[\"cell_id\"] = df[\"cell_id\"].astype(str).str.lower()\n",
    "        \n",
    "        merged_df = input_df.merge(df, on=\"cell_id\", how=\"left\")\n",
    "        \n",
    "        # Ensure required columns exist before processing\n",
    "        if \"model_prediction\" not in merged_df.columns:\n",
    "            merged_df[\"model_prediction\"] = \"N/A\"\n",
    "        if \"Capacity_Allocated(Mbps)\" not in merged_df.columns:\n",
    "            merged_df[\"Capacity_Allocated(Mbps)\"] = \"N/A\"\n",
    "        \n",
    "        # Rename columns\n",
    "        merged_df.rename(columns={\n",
    "            \"model_prediction\": \"Network Traffic Usage\",\n",
    "            \"Capacity_Allocated(Mbps)\": \"Resource Allocation (Mbps)\",\n",
    "            \"timestamp\": \"Last Updated\"\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Keep only necessary columns\n",
    "        result_df = merged_df[[\"cell_id\", \"Network Traffic Usage\", \"Resource Allocation (Mbps)\", \"Last Updated\"]]\n",
    "        result_df = result_df.sort_values(by=\"Last Updated\", ascending=False).drop_duplicates(subset=[\"cell_id\"])\n",
    "        \n",
    "        output_path = \"static/Predicted Cells.csv\"\n",
    "        result_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        return jsonify({\"download_url\": f\"/{output_path}\"})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-macosx_10_9_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/novachrono/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/novachrono/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-macosx_10_9_x86_64.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandasai 1.4 requires pandas==1.5.3, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pandas-2.2.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
